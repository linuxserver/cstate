<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><link rel="alternate" type="text/html" href="https://info.linuxserver.io"/><title>Known Issues on Info :: LinuxServer.io</title><link>https://info.linuxserver.io/affected/known-issues/</link><description>History</description><generator>github.com/cstate</generator><language>en</language><lastBuildDate>2023-12-30T18:00:00+00:00</lastBuildDate><updated>2023-12-30T18:00:00+00:00</updated><atom:link href="https://info.linuxserver.io/affected/known-issues/index.xml" rel="self" type="application/rss+xml"/><item><title>[Resolved] Known Issue: curl endless loop with 3.x Kernels</title><link>https://info.linuxserver.io/issues/2023-12-30-synology/</link><pubDate>Sat, 30 Dec 2023 18:00:00 +0000</pubDate><guid>https://info.linuxserver.io/issues/2023-12-30-synology/</guid><category>2024-01-12 12:00:00Z</category><description>Update The Alpine maintainers have backported a fixed version of the affected library to 3.19 and we have published a new version of our 3.19 base image that should resolve the issues with 3.x kernels. It will take a few days for all affected downstream images to push new builds, but any image released from this point onwards will include the fix.
Original Post There is a known issue with the version of curl currently shipped with Alpine 3.</description><content type="html">&lt;h2 id="update">Update&lt;/h2>
&lt;p>The Alpine maintainers have backported a fixed version of the affected library to 3.19 and we have published a new version of our 3.19 base image that should resolve the issues with 3.x kernels. It will take a few days for all affected downstream images to push new builds, but any image released from this point onwards will include the fix.&lt;/p>
&lt;h2 id="original-post">Original Post&lt;/h2>
&lt;p>There is a known issue with the version of curl currently shipped with Alpine 3.19 and 3.x kernels, causing an endless loop to hang containers, usually on startup. The 3.x kernel line has been End of Life since 2017, but some prebuilt systems such as older Synology NAS units are still running it. At time of posting, around 10% of our images have already been rebased to Alpine 3.19 and are therefore affected by this issue, and this number will continue to rise over the next few months.&lt;/p>
&lt;p>While a fix has been applied to the affected upstream library we do not have an ETA for if or when it will find its way into the version of curl shipped with Alpine 3.19.&lt;/p>
&lt;h3 id="workaround">Workaround&lt;/h3>
&lt;p>As a workaround you can revert to an older tag from before the image was rebased to Alpine 3.19, but please be aware that older tags do not receive updates. Refer to the Changelog in the Readme to see when the change was made for a given image. For Unraid users this will require you to edit the container and under the Advanced options change the Repository to append the required tag.&lt;/p></content></item><item><title>[Resolved] Known Issue: qBittorrent 4.6.1 Web UI Password</title><link>https://info.linuxserver.io/issues/2023-11-22-qbittorrent/</link><pubDate>Wed, 22 Nov 2023 18:00:00 +0000</pubDate><guid>https://info.linuxserver.io/issues/2023-11-22-qbittorrent/</guid><category>2023-11-30</category><description>Fix has been released, update to 4.6.2. The readme has been updated to reflect how the password for new installs are handled going forward
There is a known issue with qBittorrent 4.6.1, due to an upstream change which changes the Web UI password to a random value on startup if you have not changed it from the default. This change has been made for security reasons due to hackers exploiting users who have exposed their instances to the internet with default credentials.</description><content type="html">&lt;p>&lt;strong>Fix has been released, update to 4.6.2. The &lt;a href="https://github.com/linuxserver/docker-qbittorrent#application-setup">readme&lt;/a> has been updated to reflect how the password for new installs are handled going forward&lt;/strong>&lt;/p>
&lt;p>There is a known issue with qBittorrent 4.6.1, due to an &lt;a href="https://www.qbittorrent.org/news#mon-nov-20th-2023---qbittorrent-v4.6.1-release">upstream change&lt;/a> which changes the Web UI password to a random value on startup if you have not changed it from the default. This change has been made for security reasons due to hackers exploiting users who have exposed their instances to the internet with default credentials.&lt;/p>
&lt;p>Due to an &lt;a href="https://github.com/qbittorrent/qBittorrent/issues/19984">upstream bug&lt;/a> the generated password is not printed to the container logs, making it impossible to log in.&lt;/p>
&lt;h3 id="workaround">Workaround&lt;/h3>
&lt;p>As a workaround until a fix can be released, start the container with the &lt;code>:version-4.6.0-r0&lt;/code> image tag, login to the Web UI using the old default credentials, and change the admin account password. You will then be able to switch back to the &lt;code>:version-4.6.1-r0&lt;/code> or &lt;code>:latest&lt;/code> tags. For Unraid users this will require you to edit the container and under the Advanced options change the Repository to append the required tag; you can find step-by-step instructions &lt;a href="https://github.com/linuxserver/docker-qbittorrent/issues/268#issuecomment-1821123416">here&lt;/a>.&lt;/p></content></item><item><title>[Resolved] Known Issue: Discourse Emails</title><link>https://info.linuxserver.io/issues/2023-07-20-discourse/</link><pubDate>Thu, 20 Jul 2023 20:00:00 +0000</pubDate><guid>https://info.linuxserver.io/issues/2023-07-20-discourse/</guid><category>2023-07-20 18:15:00Z</category><description>Due to a misconfiguration that occurred during a routine restore of the database for our Discourse Forums, registered users may have recieved unwanted email notifications over the last 24 hours.
This issue has now been resolved and we apologise for any inconvenience caused.</description><content type="html">&lt;p>Due to a misconfiguration that occurred during a routine restore of the database for our &lt;a href="https://discourse.linuxserver.io/">Discourse Forums&lt;/a>, registered users may have recieved unwanted email notifications over the last 24 hours.&lt;/p>
&lt;p>This issue has now been resolved and we apologise for any inconvenience caused.&lt;/p></content></item><item><title>[Resolved] Known Issue: MariaDB Check and Repair</title><link>https://info.linuxserver.io/issues/2023-05-29-mariadb/</link><pubDate>Mon, 29 May 2023 12:00:00 +0000</pubDate><guid>https://info.linuxserver.io/issues/2023-05-29-mariadb/</guid><category>2023-09-06 21:00:00Z</category><description>There is a known issue with MariaDB when updating the container image to a new version. If a database upgrade is required and user databases are not in a healthy state, then the MariaDB service may fail to start.
MariaDB version updates (ex: 10.6.x to 10.11.x) can happen when updating the container image. Upgrading user databases is done manually by running a command.
Recovery Procedure If you have recently updated your container image and your container logs show repeating entries of:</description><content type="html">&lt;p>There is a known issue with MariaDB when updating the container image to a new version. If a database upgrade is required and user databases are not in a healthy state, then the MariaDB service may fail to start.&lt;/p>
&lt;p>MariaDB version updates (ex: &lt;code>10.6.x&lt;/code> to &lt;code>10.11.x&lt;/code>) can happen when updating the container image. Upgrading user databases is done manually by running a command.&lt;/p>
&lt;h3 id="recovery-procedure">Recovery Procedure&lt;/h3>
&lt;p>If you have recently updated your container image and your container logs show repeating entries of:&lt;/p>
&lt;pre tabindex="0">&lt;code class="language-log" data-lang="log">Caught SIGTERM signal!
&lt;/code>&lt;/pre>&lt;ul>
&lt;li>Roll back the container image to a previous tag (ex: &lt;code>lscr.io/linuxserver/mariadb:10.6.13&lt;/code> assuming this was the version you were running when things were last working)&lt;/li>
&lt;li>Run the check, repair, analyze, and optimize commands, watch for any issues&lt;/li>
&lt;li>Update the container image to the new tag (ex: &lt;code>lscr.io/linuxserver/mariadb:10.11.3&lt;/code> or &lt;code>lscr.io/linuxserver/mariadb:latest&lt;/code>)&lt;/li>
&lt;li>Run the upgrade command&lt;/li>
&lt;/ul>
&lt;p>This should get MariaDB running again with your user databases in a healthy state.&lt;/p>
&lt;h3 id="check-and-repair">Check and Repair&lt;/h3>
&lt;p>If user databases are not in a healthy state (sometimes caused by a failed upgrade), it may be remedied by running:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>mariadb-check -u root -p&amp;lt;PASSWORD&amp;gt; -c -A &lt;span style="color:#75715e"># check all databases for errors&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mariadb-check -u root -p&amp;lt;PASSWORD&amp;gt; -r -A &lt;span style="color:#75715e"># repair all databases&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mariadb-check -u root -p&amp;lt;PASSWORD&amp;gt; -a -A &lt;span style="color:#75715e"># analyze all databases&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>mariadb-check -u root -p&amp;lt;PASSWORD&amp;gt; -o -A &lt;span style="color:#75715e"># optimize all databases&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>After running the above commands, you may need to run the upgrade command again.&lt;/p>
&lt;h3 id="upgrading">Upgrading&lt;/h3>
&lt;p>When this container initializes, if &lt;code>MYSQL_ROOT_PASSWORD&lt;/code> is set an upgrade check will run. If an upgrade is required the log will indicate the need stop any services that are accessing databases in this container, and then run the command:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>mariadb-upgrade -u root -p&amp;lt;PASSWORD&amp;gt;
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="closing-notes">Closing Notes&lt;/h3>
&lt;p>If you are running MariaDB databases in production, we always recommend pinning the container image to a specific version tag, such as &lt;code>lscr.io/linuxserver/mariadb:10.6.13-r0-ls97&lt;/code>, and planning any upgrades so that you can test and monitor them.&lt;/p></content></item><item><title>[Resolved] Known Issue: Portainer &amp; Synology Docker UI</title><link>https://info.linuxserver.io/issues/2023-05-22-portainer/</link><pubDate>Mon, 22 May 2023 12:00:00 +0000</pubDate><guid>https://info.linuxserver.io/issues/2023-05-22-portainer/</guid><category>2023-11-22 18:00:00Z</category><description>Update The underlying issue still exists for both Portainer and the Synology container management UI, but the primary driver of issues has largely dissipated and so we are unpinning this notice.
Original Post There is a known issue with Portainer and the Synology Docker UI when updating (or otherwise recreating) containers, which causes them to overwrite settings in the new image with values from the old container. Creating a new container from scratch does not exhibit this behaviour.</description><content type="html">&lt;h3 id="update">Update&lt;/h3>
&lt;p>The underlying issue still exists for both Portainer and the Synology container management UI, but the primary driver of issues has largely dissipated and so we are unpinning this notice.&lt;/p>
&lt;h3 id="original-post">Original Post&lt;/h3>
&lt;p>There is a known issue with Portainer and the Synology Docker UI when updating (or otherwise recreating) containers, which causes them to overwrite settings in the new image with values from the old container. Creating a new container from scratch does not exhibit this behaviour.&lt;/p>
&lt;p>This non-standard behaviour causes containers to fail to start correctly in some cases, and may result in unexpected or unwanted configuration in others. For example, in our &lt;a href="https://github.com/linuxserver/docker-sabnzbd/issues/188">SABnzbd image&lt;/a> the &lt;code>PATH&lt;/code> environment variable is overwritten, leaving the application unable to locate the necessary Python modules to enable it to start. This is likely to become more common in the future, and there is not a practical or scalable solution that we can apply from our end to avoid this issue.&lt;/p>
&lt;p>&lt;strong>Our position remains that we provide support only for containers created and updated using Docker Compose, the Docker CLI, or using our Unraid templates, and not any 3rd party tools.&lt;/strong>&lt;/p></content></item><item><title>[Resolved] Known Issue: Heimdall 2.5.0 &amp; 2.5.1 Releases</title><link>https://info.linuxserver.io/issues/2022-11-25-heimdall/</link><pubDate>Fri, 25 Nov 2022 16:00:00 +0000</pubDate><guid>https://info.linuxserver.io/issues/2022-11-25-heimdall/</guid><category>2022-11-25 20:00:00Z</category><description>Update Version 2.5.2 has been released to fix the install issues. Users running 2.5.1 or below should look to upgrade to the version-v2.5.2 or latest tags.
Original Post There is a known issue with the Heimdall 2.5.0 and 2.5.1 releases causing broken installs for some users. If you are experiencing issues please roll back to the version-v2.4.15 tag until a fix can be published. We will update this post as necessary.</description><content type="html">&lt;h3 id="update">Update&lt;/h3>
&lt;p>Version 2.5.2 has been released to fix the install issues. Users running 2.5.1 or below should look to upgrade to the &lt;code>version-v2.5.2&lt;/code> or &lt;code>latest&lt;/code> tags.&lt;/p>
&lt;h3 id="original-post">Original Post&lt;/h3>
&lt;p>There is a known issue with the Heimdall 2.5.0 and 2.5.1 releases causing broken installs for some users. If you are experiencing issues please roll back to the &lt;code>version-v2.4.15&lt;/code> tag until a fix can be published. We will update this post as necessary.&lt;/p></content></item><item><title>[Resolved] Known Issue: lscr.io Unreachable</title><link>https://info.linuxserver.io/issues/2022-05-22-lscr/</link><pubDate>Sun, 22 May 2022 16:00:00 +0000</pubDate><guid>https://info.linuxserver.io/issues/2022-05-22-lscr/</guid><category>2022-05-22 18:00:00Z</category><description>Update DNS propagation has completed and all services should now be accessible. If you&amp;rsquo;re still experiencing connection issues please clear your DNS cache and try again.
Original Post Due to an issue with our domain registrar the lscr.io domain is has been unreachable for part of the day. The underlying problem has been resolved and we are now waiting for DNS propagation to complete so that we can resume normal operations.</description><content type="html">&lt;h3 id="update">Update&lt;/h3>
&lt;p>DNS propagation has completed and all services should now be accessible. If you&amp;rsquo;re still experiencing connection issues please clear your DNS cache and try again.&lt;/p>
&lt;h3 id="original-post">Original Post&lt;/h3>
&lt;p>Due to an issue with our domain registrar the lscr.io domain is has been unreachable for part of the day. The underlying problem has been resolved and we are now waiting for DNS propagation to complete so that we can resume normal operations.&lt;/p>
&lt;p>If you are experiencing issues with pulling images from lscr.io you can use ghcr.io, docker.io, or any other mirror in the interim.&lt;/p></content></item><item><title>[Resolved] Known Issue: nzbhydra2 Stable v4.3.1-ls52 and later</title><link>https://info.linuxserver.io/issues/2022-05-05-nzbhydra2/</link><pubDate>Thu, 05 May 2022 12:00:00 +0000</pubDate><guid>https://info.linuxserver.io/issues/2022-05-05-nzbhydra2/</guid><category>2022-05-22 16:00:00Z</category><description>Update We have identified the root cause of the issue and documented the available solutions here: https://docs.linuxserver.io/faq#jammy
Original Post There is a known compatibility issue with our nzbhydra2 image Stable branch versions v4.3.1-ls52 and later and older versions of the Docker engine on some amd64 platforms. If you experience Java errors on startup in the form of:
ERROR - Unable to determine java version; make sure Java is installed and callable.</description><content type="html">&lt;h3 id="update">Update&lt;/h3>
&lt;p>We have identified the root cause of the issue and documented the available solutions here: &lt;a href="https://docs.linuxserver.io/faq#jammy">https://docs.linuxserver.io/faq#jammy&lt;/a>&lt;/p>
&lt;h3 id="original-post">Original Post&lt;/h3>
&lt;p>There is a known compatibility issue with our nzbhydra2 image Stable branch versions &lt;code>v4.3.1-ls52&lt;/code> and later and older versions of the Docker engine on some amd64 platforms. If you experience Java errors on startup in the form of:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-shell" data-lang="shell">&lt;span style="display:flex;">&lt;span>ERROR - Unable to determine java version; make sure Java is installed and callable.
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Please ensure that your Docker install is updated to at least version &lt;code>20.10.10&lt;/code>. We will update this issue as and when more information is available.&lt;/p></content></item><item><title>[Resolved] Known Issue: Deluge 2.0.4</title><link>https://info.linuxserver.io/issues/2021-12-14-deluge/</link><pubDate>Tue, 14 Dec 2021 14:00:00 +0000</pubDate><guid>https://info.linuxserver.io/issues/2021-12-14-deluge/</guid><category>2021-12-15</category><description>Version 2.0.5 has been released to resolve this issue.
An upstream issue with deluge-web in version 2.0.4 has broken the deluge webui for users. Please roll back to the version-2.0.3-2201906121747ubuntu18.04.1 tag until a fix is published.</description><content type="html">&lt;p>Version 2.0.5 has been released to resolve this issue.&lt;/p>
&lt;blockquote>
&lt;p>An upstream issue with deluge-web in version 2.0.4 has broken the deluge webui for users. Please roll back to the &lt;code>version-2.0.3-2201906121747ubuntu18.04.1&lt;/code> tag until a fix is published.&lt;/p>
&lt;/blockquote></content></item><item><title>[Resolved] Known Issue: Paperless-ng</title><link>https://info.linuxserver.io/issues/2021-07-26-paperless-ng/</link><pubDate>Mon, 26 Jul 2021 00:00:00 +0000</pubDate><guid>https://info.linuxserver.io/issues/2021-07-26-paperless-ng/</guid><category>2021-07-30</category><description>The initial release of our paperless-ng container did not correctly map the contents of /config with the config mount point. We are pushing an update to correct this issue, however, users will need to manually copy out their configuration files or else there will be data loss. You copy out all necessary files by running the following command:
docker cp paperless-ng:/app/paperless/data/db.sqlite3 . This will copy the existing database to your current working directory.</description><content type="html">&lt;p>The initial release of our paperless-ng container did not correctly map the contents of /config with the config mount point. We are pushing an update to correct this issue, however, users will need to manually copy out their configuration files or else there will be data loss. You copy out all necessary files by running the following command:&lt;/p>
&lt;pre tabindex="0">&lt;code>docker cp paperless-ng:/app/paperless/data/db.sqlite3 .
&lt;/code>&lt;/pre>&lt;p>This will copy the existing database to your current working directory. You can then safely place this file into the /config mount of paperless-ng and safely update.&lt;/p></content></item><item><title>[Resolved] Known Issue: Swag 1.15.0</title><link>https://info.linuxserver.io/issues/2021-05-29-swag/</link><pubDate>Sat, 29 May 2021 00:00:00 +0000</pubDate><guid>https://info.linuxserver.io/issues/2021-05-29-swag/</guid><category>2021-06-02</category><description>Version 1.16 has been released to resolve this issue.
An upstream issue with certbot has broken some of the DNS validation plugins used by swag. If you are affected by this issue, please roll back to version-1.14.0 until 1.16 is released.</description><content type="html">&lt;p>Version 1.16 has been released to resolve this issue.&lt;/p>
&lt;blockquote>
&lt;p>An upstream issue with certbot has broken some of the DNS validation plugins used by swag. If you are affected by this issue, please roll back to &lt;code>version-1.14.0&lt;/code> until 1.16 is released.&lt;/p>
&lt;/blockquote></content></item><item><title>[Resolved] Known Issue: Unifi Controller v6.2.23</title><link>https://info.linuxserver.io/issues/2021-05-13-unifi-controller/</link><pubDate>Sat, 08 May 2021 00:00:00 +0000</pubDate><guid>https://info.linuxserver.io/issues/2021-05-13-unifi-controller/</guid><category>2021-05-14</category><description>Ubiquiti have released v6.2.25 to resolve the issues with their original broken release.
Ubiquiti have pulled the v6.2.23 update for their Unifi Controller software due to issues with upgrading from older versions. If you have already updated your container image you will need to pull the re-released v6.1.71 and restore your config from a backup.</description><content type="html">&lt;p>Ubiquiti have released v6.2.25 to resolve the issues with their original broken release.&lt;/p>
&lt;blockquote>
&lt;p>Ubiquiti have pulled the v6.2.23 update for their Unifi Controller software due to issues with upgrading from older versions. If you have already updated your container image you will need to pull the re-released v6.1.71 and restore your config from a backup.&lt;/p>
&lt;/blockquote></content></item></channel></rss>